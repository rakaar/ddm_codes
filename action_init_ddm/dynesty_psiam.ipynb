{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynesty import NestedSampler\n",
    "from dynesty import plotting as dyplot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from psiam_utils import rho_A_t_fn, rho_E_t_fn, cum_A_t_fn, rho_E_minus_t_fn, P_large_t_btn_1_2\n",
    "from scipy.integrate import quad\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsiam_data_5k_1.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     psiam_data \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      5\u001b[0m choices \u001b[38;5;241m=\u001b[39m psiam_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m RTs \u001b[38;5;241m=\u001b[39m psiam_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRTs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "with open('psiam_data_5k_1.pkl', 'rb') as f:\n",
    "    psiam_data = pickle.load(f)\n",
    "\n",
    "\n",
    "choices = psiam_data['choices']\n",
    "RTs = psiam_data['RTs']\n",
    "is_act_resp = psiam_data['is_act_resp']\n",
    "V_A = psiam_data['V_A']\n",
    "theta_A = psiam_data['theta_A']\n",
    "V_E = psiam_data['V_E']\n",
    "theta_E = psiam_data['theta_E']\n",
    "Z_E = psiam_data['Z_E']\n",
    "t_stim = psiam_data['t_stim']\n",
    "\n",
    "\n",
    "indices_evid = np.where(is_act_resp == 0)[0]\n",
    "RTs_evid = RTs[indices_evid].flatten()\n",
    "\n",
    "indices_act = np.where(is_act_resp == 1)[0]\n",
    "RTs_act = RTs[indices_act].flatten()\n",
    "\n",
    "\n",
    "RTs = RTs.flatten()\n",
    "\n",
    "correct_idx = np.where(choices == 1)[0]\n",
    "wrong_idx = np.where(choices == -1)[0]\n",
    "\n",
    "\n",
    "correct_RT = RTs[correct_idx]\n",
    "wrong_RT = RTs[wrong_idx]\n",
    "\n",
    "abort_idx = np.where(RTs < t_stim)[0]\n",
    "abort_RT = RTs[abort_idx]\n",
    "\n",
    "print(f\"V_A: {V_A}\")\n",
    "print(f\"theta_A: {theta_A}\")\n",
    "print(f\"V_E: {V_E}\")\n",
    "print(f\"theta_E: {theta_E}\")\n",
    "print(f\"Num of AI process: {is_act_resp.sum()}/{len(is_act_resp)}\")\n",
    "print(f\"t start is {t_stim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounds used for BADs\n",
    "V_A_bounds = [0.1, 3]; V_A_plausible_bounds = [0.5, 1.5]\n",
    "theta_A_bounds = [1, 3]; theta_A_plausible_bounds = [1.5, 2.5]\n",
    "V_E_bounds = [-5, 5]; V_E_plausible_bounds = [-2, 2]\n",
    "theta_E_bounds = [0.1, 5]; theta_E_plausible_bounds = [0.5,1.5]\n",
    "Z_bounds = [-0.5, 0.5]; Z_plausible_bounds = [-0.2, 0.2]\n",
    "\n",
    "def transform_random_number(u, a, b):\n",
    "    return (b-a)*u + a \n",
    "\n",
    "def psiam_prior_fn(u):\n",
    "    priors = np.zeros_like(u)\n",
    "    \n",
    "    priors[0] = transform_random_number(u[0], V_A_bounds[0], V_A_bounds[1])\n",
    "    priors[1] = transform_random_number(u[1], theta_A_bounds[0], theta_A_bounds[1])\n",
    "    priors[2] = transform_random_number(u[2], V_E_bounds[0], V_E_bounds[1])\n",
    "    priors[3] = transform_random_number(u[3], theta_E_bounds[0], theta_E_bounds[1])\n",
    "    priors[4] = transform_random_number(u[4], Z_bounds[0], Z_bounds[1])\n",
    "\n",
    "    return priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_abort_loglike(t, V_A, theta_A, t_a, V_E, theta_E, K_max, t_stim, Z, t_E, abort_norm_term):\n",
    "    P_A = rho_A_t_fn(t, V_A, theta_A, t_a)\n",
    "    C_E = quad(rho_E_t_fn, 0, t, args=(V_E, theta_E, K_max, t_stim))[0]\n",
    "    P_E = rho_E_t_fn(t, V_E, theta_E, K_max, t_stim, Z, t_E)\n",
    "    C_A = cum_A_t_fn(t, V_A, theta_A, t_a)\n",
    "    p_abort = P_A * (1 - C_E) + P_E * (1 - C_A)\n",
    "    if p_abort <= 0:\n",
    "        p_abort = 1e-6\n",
    "    return np.log(p_abort / abort_norm_term)\n",
    "\n",
    "def calculate_correct_loglike(t, V_A, theta_A, t_a, V_E, theta_E, Z, K_max, t_stim, t_E, correct_norm_term):\n",
    "    P_A = rho_A_t_fn(t, V_A, theta_A, t_a)\n",
    "    P_E_btn_1_2 = P_large_t_btn_1_2(1, 2, t, V_E, theta_E, Z, K_max, t_stim)\n",
    "    P_E_plus = rho_E_minus_t_fn(t, -V_E, theta_E, K_max, t_stim, -Z, t_E)\n",
    "    C_A = cum_A_t_fn(t, V_A, theta_A, t_a)\n",
    "    p_correct = P_A * P_E_btn_1_2 + P_E_plus * (1 - C_A)\n",
    "    if p_correct <= 0:\n",
    "        p_correct = 1e-6\n",
    "    return np.log(p_correct / correct_norm_term)\n",
    "\n",
    "def calculate_wrong_loglike(t, V_A, theta_A, t_a, V_E, theta_E, Z, K_max, t_stim, t_E, wrong_norm_term):\n",
    "    P_A = rho_A_t_fn(t, V_A, theta_A, t_a)\n",
    "    P_E_btn_0_1 = P_large_t_btn_1_2(0, 1, t, V_E, theta_E, Z, K_max, t_stim)\n",
    "    P_E_minus = rho_E_minus_t_fn(t, V_E, theta_E, K_max, t_stim, Z, t_E)\n",
    "    C_A = cum_A_t_fn(t, V_A, theta_A, t_a)\n",
    "    p_wrong = P_A * P_E_btn_0_1 + P_E_minus * (1 - C_A)\n",
    "    if p_wrong <= 0:\n",
    "        p_wrong = 1e-6\n",
    "    return np.log(p_wrong / wrong_norm_term)\n",
    "\n",
    "\n",
    "\n",
    "def psiam_loglike_fn(params):\n",
    "    V_A, theta_A, V_E, theta_E, Z = params\n",
    "    # hyperparams\n",
    "    t_a = 0; t_E = 0; \n",
    "    K_max = 10\n",
    "    \n",
    "    # norm terms\n",
    "    N = len(RTs)\n",
    "    N_abort = len(abort_RT)\n",
    "    N_correct = len(correct_RT)\n",
    "    N_wrong = len(wrong_RT)\n",
    "\n",
    "    abort_norm_term = N_abort/N\n",
    "    correct_norm_term = N_correct/N\n",
    "    wrong_norm_term = N_wrong/N\n",
    "\n",
    "    # abort_loglike = sum(Parallel(n_jobs=n_jobs)(\n",
    "    #     delayed(calculate_abort_loglike)(t, V_A, theta_A, t_a, V_E, theta_E, K_max, t_stim, Z, t_E, abort_norm_term)\n",
    "    #     for t in abort_RT\n",
    "    # ))\n",
    "    abort_loglike = 0\n",
    "    for t in abort_RT:\n",
    "        abort_loglike += calculate_abort_loglike(t, V_A, theta_A, t_a, V_E, theta_E, K_max, t_stim, Z, t_E, abort_norm_term)\n",
    "\n",
    "    # correct_loglike = sum(Parallel(n_jobs=n_jobs)(\n",
    "    #     delayed(calculate_correct_loglike)(t, V_A, theta_A, t_a, V_E, theta_E, Z, K_max, t_stim, t_E, correct_norm_term)\n",
    "    #     for t in correct_RT\n",
    "    # ))\n",
    "    correct_loglike = 0\n",
    "    for t in correct_RT:\n",
    "        correct_loglike += calculate_correct_loglike(t, V_A, theta_A, t_a, V_E, theta_E, Z, K_max, t_stim, t_E, correct_norm_term)\n",
    "\n",
    "    # wrong_loglike = sum(Parallel(n_jobs=n_jobs)(\n",
    "    #     delayed(calculate_wrong_loglike)(t, V_A, theta_A, t_a, V_E, theta_E, Z, K_max, t_stim, t_E, wrong_norm_term)\n",
    "    #     for t in wrong_RT\n",
    "    # ))\n",
    "    wrong_loglike = 0\n",
    "    for t in wrong_RT:\n",
    "        wrong_loglike += calculate_wrong_loglike(t, V_A, theta_A, t_a, V_E, theta_E, Z, K_max, t_stim, t_E, wrong_norm_term)\n",
    "\n",
    "    total_loglike = abort_loglike + correct_loglike + wrong_loglike\n",
    "\n",
    "\n",
    "    if np.isnan(total_loglike):\n",
    "        raise ValueError(\"Log-likelihood is NaN or infinite.\")\n",
    "    if np.isinf(total_loglike):\n",
    "        raise ValueError(\"Log-likelihood is infinite.\")\n",
    "\n",
    "    return total_loglike\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loglike = -8337.297015813281\n",
      "Time taken: 1.505448 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "result = psiam_loglike_fn([V_A, theta_A, V_E, theta_E, Z_E])\n",
    "end_time = time.time()\n",
    "\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "print(f'loglike = {result}')\n",
    "print(f'Time taken: {time_taken:.6f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1807it [2:05:41,  4.17s/it, bound: 0 | nc: 18 | ncall: 17281 | eff(%): 10.457 | loglstar:   -inf < 52621.451 <    inf | logz: 52610.933 +/-  0.145 | dlogz: 83733.580 >  0.509]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      4\u001b[0m sampler \u001b[38;5;241m=\u001b[39m NestedSampler(psiam_loglike_fn, psiam_prior_fn, ndim, pool\u001b[38;5;241m=\u001b[39mpool, queue_size\u001b[38;5;241m=\u001b[39mnum_process)\n\u001b[0;32m----> 5\u001b[0m \u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m pool\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m      7\u001b[0m pool\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dynesty/sampler.py:1020\u001b[0m, in \u001b[0;36mSampler.run_nested\u001b[0;34m(self, maxiter, maxcall, dlogz, logl_max, n_effective, add_live, print_progress, print_func, save_bounds, checkpoint_file, checkpoint_every, resume)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1019\u001b[0m     ncall \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mncall\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m it, results \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m   1021\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[1;32m   1022\u001b[0m                         maxcall\u001b[38;5;241m=\u001b[39mmaxcall,\n\u001b[1;32m   1023\u001b[0m                         dlogz\u001b[38;5;241m=\u001b[39mdlogz,\n\u001b[1;32m   1024\u001b[0m                         logl_max\u001b[38;5;241m=\u001b[39mlogl_max,\n\u001b[1;32m   1025\u001b[0m                         save_bounds\u001b[38;5;241m=\u001b[39msave_bounds,\n\u001b[1;32m   1026\u001b[0m                         save_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1027\u001b[0m                         n_effective\u001b[38;5;241m=\u001b[39mn_effective,\n\u001b[1;32m   1028\u001b[0m                         resume\u001b[38;5;241m=\u001b[39mresume,\n\u001b[1;32m   1029\u001b[0m                         add_live\u001b[38;5;241m=\u001b[39madd_live)):\n\u001b[1;32m   1030\u001b[0m         ncall \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mnc\n\u001b[1;32m   1032\u001b[0m         \u001b[38;5;66;03m# Print progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dynesty/sampler.py:843\u001b[0m, in \u001b[0;36mSampler.sample\u001b[0;34m(self, maxiter, maxcall, dlogz, logl_max, n_effective, add_live, save_bounds, save_samples, resume)\u001b[0m\n\u001b[1;32m    838\u001b[0m     old_blob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    840\u001b[0m \u001b[38;5;66;03m# Sample a new live point from within the likelihood constraint\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# `logl > loglstar` using the bounding distribution and sampling\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# method from our sampler.\u001b[39;00m\n\u001b[0;32m--> 843\u001b[0m u, v, logl, nc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloglstar_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m ncall \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m nc\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mncall \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m nc\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dynesty/sampler.py:421\u001b[0m, in \u001b[0;36mSampler._new_point\u001b[0;34m(self, loglstar)\u001b[0m\n\u001b[1;32m    418\u001b[0m ncall_accum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;66;03m# Get the next point from the queue\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m     u, v, logl, nc, blob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_point_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloglstar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m     ncall \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m nc\n\u001b[1;32m    423\u001b[0m     ncall_accum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m nc\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dynesty/sampler.py:404\u001b[0m, in \u001b[0;36mSampler._get_point_value\u001b[0;34m(self, loglstar)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# If the queue is empty, refill it.\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnqueue \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 404\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fill_queue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloglstar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;66;03m# Grab the earliest entry.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m u, v, logl, nc, blob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqueue\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dynesty/sampler.py:397\u001b[0m, in \u001b[0;36mSampler._fill_queue\u001b[0;34m(self, loglstar)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqueue_size):\n\u001b[1;32m    388\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    389\u001b[0m         SamplerArgument(u\u001b[38;5;241m=\u001b[39mpoint_queue[i],\n\u001b[1;32m    390\u001b[0m                         loglstar\u001b[38;5;241m=\u001b[39mloglstar,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m                         rseed\u001b[38;5;241m=\u001b[39mseeds[i],\n\u001b[1;32m    396\u001b[0m                         kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs))\n\u001b[0;32m--> 397\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqueue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mmapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevolve_point\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_process = os.cpu_count()\n",
    "pool = multiprocessing.Pool(processes=num_process)\n",
    "ndim = 5\n",
    "sampler = NestedSampler(psiam_loglike_fn, psiam_prior_fn, ndim, pool=pool, queue_size=num_process)\n",
    "sampler.run_nested()\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

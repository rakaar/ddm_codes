{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynesty import NestedSampler\n",
    "from dynesty import plotting as dyplot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from psiam_utils import rho_A_t_fn, rho_E_t_fn, cum_A_t_fn, rho_E_minus_t_fn, P_large_t_btn_1_2\n",
    "from scipy.integrate import quad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_A: 1\n",
      "theta_A: 2\n",
      "V_E: 0.5\n",
      "theta_E: 1\n",
      "Num of AI process: 3765/10000\n",
      "t start is 0.5\n"
     ]
    }
   ],
   "source": [
    "with open('psiam_data_5k_2.pkl', 'rb') as f:\n",
    "    psiam_data = pickle.load(f)\n",
    "\n",
    "\n",
    "choices = psiam_data['choices']\n",
    "RTs = psiam_data['RTs']\n",
    "is_act_resp = psiam_data['is_act_resp']\n",
    "V_A = psiam_data['V_A']\n",
    "theta_A = psiam_data['theta_A']\n",
    "V_E = psiam_data['V_E']\n",
    "theta_E = psiam_data['theta_E']\n",
    "Z_E = psiam_data['Z_E']\n",
    "t_stim = psiam_data['t_stim']\n",
    "\n",
    "\n",
    "indices_evid = np.where(is_act_resp == 0)[0]\n",
    "RTs_evid = RTs[indices_evid].flatten()\n",
    "\n",
    "indices_act = np.where(is_act_resp == 1)[0]\n",
    "RTs_act = RTs[indices_act].flatten()\n",
    "\n",
    "\n",
    "RTs = RTs.flatten()\n",
    "\n",
    "correct_idx = np.where(choices == 1)[0]\n",
    "wrong_idx = np.where(choices == -1)[0]\n",
    "\n",
    "\n",
    "correct_RT = RTs[correct_idx]\n",
    "wrong_RT = RTs[wrong_idx]\n",
    "\n",
    "abort_idx = np.where(RTs < t_stim)[0]\n",
    "abort_RT = RTs[abort_idx]\n",
    "\n",
    "print(f\"V_A: {V_A}\")\n",
    "print(f\"theta_A: {theta_A}\")\n",
    "print(f\"V_E: {V_E}\")\n",
    "print(f\"theta_E: {theta_E}\")\n",
    "print(f\"Num of AI process: {is_act_resp.sum()}/{len(is_act_resp)}\")\n",
    "print(f\"t start is {t_stim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounds used for BADs\n",
    "V_A_bounds = [0.1, 3]; V_A_plausible_bounds = [0.5, 1.5]\n",
    "theta_A_bounds = [1, 3]; theta_A_plausible_bounds = [1.5, 2.5]\n",
    "V_E_bounds = [-5, 5]; V_E_plausible_bounds = [-2, 2]\n",
    "theta_E_bounds = [0.1, 5]; theta_E_plausible_bounds = [0.5,1.5]\n",
    "Z_bounds = [-0.5, 0.5]; Z_plausible_bounds = [-0.2, 0.2]\n",
    "\n",
    "def transform_random_number(u, a, b):\n",
    "    return (b-a)*u + a \n",
    "\n",
    "def prior_transform(u):\n",
    "    priors = np.zeros_like(u)\n",
    "    \n",
    "    priors[0] = transform_random_number(u[0], V_A_bounds[0], V_A_bounds[1])\n",
    "    priors[1] = transform_random_number(u[1], theta_A_bounds[0], theta_A_bounds[1])\n",
    "    priors[2] = transform_random_number(u[2], V_E_bounds[0], V_E_bounds[1])\n",
    "    priors[3] = transform_random_number(u[3], theta_E_bounds[0], theta_E_bounds[1])\n",
    "    priors[4] = transform_random_number(u[4], Z_bounds[0], Z_bounds[1])\n",
    "\n",
    "    return priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_abort_loglike(t, V_A, theta_A, t_a, V_E, theta_E, K_max, t_stim, Z, t_E, abort_norm_term):\n",
    "    P_A = rho_A_t_fn(t, V_A, theta_A, t_a)\n",
    "    C_E = quad(rho_E_t_fn, 0, t, args=(V_E, theta_E, K_max, t_stim))[0]\n",
    "    P_E = rho_E_t_fn(t, V_E, theta_E, K_max, t_stim, Z, t_E)\n",
    "    C_A = cum_A_t_fn(t, V_A, theta_A, t_a)\n",
    "    p_abort = P_A * (1 - C_E) + P_E * (1 - C_A)\n",
    "    if p_abort <= 0:\n",
    "        p_abort = 1e-6\n",
    "    return np.log(p_abort / abort_norm_term)\n",
    "\n",
    "def calculate_correct_loglike(t, V_A, theta_A, t_a, V_E, theta_E, Z, K_max, t_stim, t_E, correct_norm_term):\n",
    "    P_A = rho_A_t_fn(t, V_A, theta_A, t_a)\n",
    "    P_E_btn_1_2 = P_large_t_btn_1_2(1, 2, t, V_E, theta_E, Z, K_max, t_stim)\n",
    "    P_E_plus = rho_E_minus_t_fn(t, -V_E, theta_E, K_max, t_stim, -Z, t_E)\n",
    "    C_A = cum_A_t_fn(t, V_A, theta_A, t_a)\n",
    "    p_correct = P_A * P_E_btn_1_2 + P_E_plus * (1 - C_A)\n",
    "    if p_correct <= 0:\n",
    "        p_correct = 1e-6\n",
    "    return np.log(p_correct / correct_norm_term)\n",
    "\n",
    "def calculate_wrong_loglike(t, V_A, theta_A, t_a, V_E, theta_E, Z, K_max, t_stim, t_E, wrong_norm_term):\n",
    "    P_A = rho_A_t_fn(t, V_A, theta_A, t_a)\n",
    "    P_E_btn_0_1 = P_large_t_btn_1_2(0, 1, t, V_E, theta_E, Z, K_max, t_stim)\n",
    "    P_E_minus = rho_E_minus_t_fn(t, V_E, theta_E, K_max, t_stim, Z, t_E)\n",
    "    C_A = cum_A_t_fn(t, V_A, theta_A, t_a)\n",
    "    p_wrong = P_A * P_E_btn_0_1 + P_E_minus * (1 - C_A)\n",
    "    if p_wrong <= 0:\n",
    "        p_wrong = 1e-6\n",
    "    return np.log(p_wrong / wrong_norm_term)\n",
    "\n",
    "\n",
    "\n",
    "def psiam_loglike_fn(params):\n",
    "    V_A, theta_A, V_E, theta_E, Z = params\n",
    "    # hyperparams\n",
    "    t_a = 0; t_E = 0; \n",
    "    K_max = 10\n",
    "    \n",
    "    # norm terms\n",
    "    N = len(RTs)\n",
    "    N_abort = len(abort_RT)\n",
    "    N_correct = len(correct_RT)\n",
    "    N_wrong = len(wrong_RT)\n",
    "\n",
    "    abort_norm_term = N_abort/N\n",
    "    correct_norm_term = N_correct/N\n",
    "    wrong_norm_term = N_wrong/N\n",
    "    n_jobs = -1  \n",
    "\n",
    "    abort_loglike = sum(Parallel(n_jobs=n_jobs)(\n",
    "        delayed(calculate_abort_loglike)(t, V_A, theta_A, t_a, V_E, theta_E, K_max, t_stim, Z, t_E, abort_norm_term)\n",
    "        for t in abort_RT\n",
    "    ))\n",
    "\n",
    "    correct_loglike = sum(Parallel(n_jobs=n_jobs)(\n",
    "        delayed(calculate_correct_loglike)(t, V_A, theta_A, t_a, V_E, theta_E, Z, K_max, t_stim, t_E, correct_norm_term)\n",
    "        for t in correct_RT\n",
    "    ))\n",
    "\n",
    "    wrong_loglike = sum(Parallel(n_jobs=n_jobs)(\n",
    "        delayed(calculate_wrong_loglike)(t, V_A, theta_A, t_a, V_E, theta_E, Z, K_max, t_stim, t_E, wrong_norm_term)\n",
    "        for t in wrong_RT\n",
    "    ))\n",
    "\n",
    "    total_loglike = abort_loglike + correct_loglike + wrong_loglike\n",
    "\n",
    "    if np.isnan(total_loglike):\n",
    "        raise ValueError(\"Log-likelihood is NaN or infinite.\")\n",
    "    if np.isinf(total_loglike):\n",
    "        raise ValueError(\"Log-likelihood is infinite.\")\n",
    "\n",
    "    return total_loglike\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
